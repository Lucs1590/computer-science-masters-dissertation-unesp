\newpage
\clearpage

\section{RESULTADOS E DISCUSSÕES}
\label{results}
Neste capítulo, dedicado a Resultados e Discussões, serão apresentados e analisados os resultados dos experimentos realizados no transcurso deste estudo, acompanhados de uma reflexão criteriosa sobre os dados obtidos. Nesta etapa, será possível, portanto, avaliar a eficácia dos métodos que foram propostos e implementados, além de discutir as ideias futuras de implementação e as perspectivas coletadas para a evolução do tema em questão.

A estrutura do capítulo é delineada em seções que facilitam a compreensão dos resultados de acordo com o contexto do experimento aplicado. Na Seção \ref{results:class}, será discutido sobre os experimentos realizados prioritariamente para a tarefa de classificação. Esses experimentos iniciais foram fundamentais para balizar as análises e refinamentos subsequentes da técnica proposta.

Na sequência, a Seção \ref{results:semantic} irá abordar os resultados obtidos nos experimentos que se destinam diretamente à área de segmentação, que constitui o núcleo da aplicação da técnica proposta. Aqui, expandiremos o foco para a parcela mais crítica de nossa pesquisa, apresentando a eficácia de nosso método na tarefa de segmentação semântica de imagens.

Por fim, na Seção \ref{result:final} proporcionaremos as considerações finais em relação as seções anteriores, salientando às implicações dos resultados no campo de estudo do trabalho.

\subsection{Resultados da Classificação de Imagens}
\label{results:class}
Os experimentos e resultados desta seção fornecem valiosas percepções sobre o desempenho do método BPCAPooling em comparação com as estratégias de \textit{pooling} convencionais (\textit{Avg Pooling} e \textit{Max Pooling}) \citep{Ozdemir2023Avg-topk:Networks} quando aplicados na arquitetura VGG-16 para a tarefa de classificação.

Ao analisar o desempenho do modelo treinado no conjunto de dados CIFAR 100 utilizando o método proposto, observamos uma tendência indesejada. Este modelo apresentou a maior perda e a menor precisão quando comparado aos modelos utilizando os métodos \textit{Avg Pooling} e \textit{Max Pooling} no processo de descongelamento do terceiro bloco convolucional. Os resultados são evidenciados na parte de aquecimento do processo de \textit{fine-tuning} na Tabela \ref{results:class:tab:2}.

Mesmo após a conclusão do processo de \textit{fine-tuning} completo, o modelo treinado com a técnica BPCAPooling apresentou resultados inferiores, conforme evidenciado na Tabela \ref{results:class:tab:2}. Os métodos Max Pooling e Avg Pooling continuaram a demonstrar uma superioridade significativa em relação ao método BPCAPooling. Os resultados mais promissores foram obtidos pela arquitetura VGG-16 com o método Max Pooling. A análise detalhada dos motivos subjacentes a essa discrepância será discutida na Seção \ref{results:class:datasets}.

\begin{table}[H]
    \centering
    \caption{Resultados por fase de \textit{fine-tuning} de VGG-16 aplicada no conjunto de dados CIFAR 100.}
    \label{results:class:tab:2}
    \resizebox{1\textwidth}{!}{
    \begin{tabular}{l|l|l|l|l|l|l|l|l}
    \multicolumn{1}{c|}{\textbf{Método de \textit{Pooling}}} & \multicolumn{2}{c|}{\textbf{Aquecimento}}                                          & \multicolumn{2}{c|}{\textbf{Bloco 5}}                                          & \multicolumn{2}{c|}{\textbf{Bloco 4}}                                          & \multicolumn{2}{c}{\textbf{Bloco 3}}                                          \\
    \cline{2-9}
    \multicolumn{1}{c|}{\textbf{}}                & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c|}{\textbf{\textit{Loss}}} & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c|}{\textbf{\textit{Loss}}} & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c|}{\textbf{\textit{Loss}}} & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c}{\textbf{\textit{Loss}}} \\
    \hline
    \textit{Avg Pooling}                                   &                                    36,300 &                            2,7309 &                                    39,340 &                            2,4971 &                                    41,371 &                            2,2958 &                                    42,371 &                            2,2364 \\
    BPCAPooling                                            &                                    14,471 &                            3,7645 &                                    15,185 &                            3,6677 &                                    16,229 &                            3,6020 &                                    17,543 &                            3,5121 \\
    \textit{Max Pooling}                                   &                                    39,857 &                            2,0481 &                                    43,671 &                            1,7166 &                                    45,100 &                            1,5448 &                                    \textbf{46,071} &                            \textbf{1,4862} 
    \end{tabular}}

    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}

Para o conjunto de dados \textit{Food}-101, os resultados não divergiram muito dos obtidos no primeiro conjunto de dados. Durante a fase inicial do treinamento, os resultados do método proposto já se mostraram desafiadores em comparação aos outros métodos, como pode ser observado na parte de aquecimento da Tabela \ref{results:class:tab:4}.

No contexto da aplicação do processo de \textit{fine-tuning}, observa-se consistentemente que o modelo de \textit{pooling} proposto demonstrou desempenho inferior em todas as fases quando comparado ao melhor método, que continuou sendo a junção de VGG-16 com \textit{Max Pooling}, conforme ilustrado na Tabela \ref{results:class:tab:4}.

\begin{table}[H]
    \centering
    \caption{Resultados por fase de \textit{fine-tuning} de VGG-16 aplicada no conjunto de dados \textit{Food}-101.}
    \label{results:class:tab:4}
    \resizebox{1\textwidth}{!}{
    \begin{tabular}{l|l|l|l|l|l|l|l|l}
    \multicolumn{1}{c|}{\textbf{Método de \textit{Pooling}}} & \multicolumn{2}{c|}{\textbf{Aquecimento}}                                          & \multicolumn{2}{c|}{\textbf{Bloco 5}}                                          & \multicolumn{2}{c|}{\textbf{Bloco 4}}                                          & \multicolumn{2}{c}{\textbf{Bloco 3}}                                          \\
    \cline{2-9}
    \multicolumn{1}{c|}{\textbf{}}                & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c|}{\textbf{\textit{Loss}}} & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c|}{\textbf{\textit{Loss}}} & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c|}{\textbf{\textit{Loss}}} & \multicolumn{1}{c|}{\textbf{Acurácia(\%)}} & \multicolumn{1}{c}{\textbf{\textit{Loss}}} \\
    \hline
    BPCAPooling                                   &                                    3,8586 &                            4,7057 &                                    4,3395 &                            4,6632 &                                    4,4130 &	                           4,4404 &                                    3,423  &	                           4,5187 \\
    Max Pooling                                   &                                    41,623 &                            2,3718 &                                    49,471 &                            \textbf{2,2033} &                                    \textbf{50,080} &                            2,3745 &                                    50,031 &                            2,4335 
    \end{tabular}}

    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}

Na Tabela \ref{results:class:tab:4}, observa-se um comportamento distinto em comparação ao primeiro conjunto de dados. Os resultados de maior acurácia estão representados no quarto bloco, não no último bloco adicionado, o que levanta questionamentos sobre a influência desse bloco, assunto que será discutido na Seção \ref{results:class:datasets}.

Em relação ao custo computacional, observou-se que o método proposto, desenvolvido utilizando o \textit{framework} Tensorflow, exigiu um processamento considerável, resultando em desempenho mais lento durante os testes devido ao aumento da complexidade. Por exemplo, no caso do conjunto de dados CIFAR 100, com o descongelamento de blocos e $700$ épocas utilizando a configuração de \textit{hardware} de referência, os métodos \textit{Max Pooling} e \textit{Avg Pooling} levaram cerca de $7$ horas para serem executados. Em contrapartida, o BPCAPooling exigiu aproximadamente $19$ horas, cerca de $2,71$ vezes mais tempo, ressaltando que o conjunto de dados CIFAR 100 é otimizado para processamento em GPU.

Resultados semelhantes foram observados no conjunto de dados \textit{Food}-101, onde \textit{Max Pooling} e \textit{Avg Pooling} levaram cerca de $33$ horas para o processo de treinamento e validação, enquanto o BPCAPooling demandou aproximadamente \textit{38} horas. O aumento no tempo de processamento se deve principalmente ao tamanho maior das imagens. É importante mencionar que este conjunto de dados não está otimizado para processamento em GPU, o que resulta em um desempenho do \textit{hardware} abaixo do ideal.

Apesar dos resultados inesperados em relação ao método BPCAPooling, alguns \textit{insights} puderam ser extraídos das fases de treinamento e validação. Esses pontos de introspecção serão abordados a seguir nesta seção, juntamente com informações sobre a influência da aplicação desse método nas características específicas dos diferentes conjuntos de dados (Seção \ref{results:class:datasets}) e a exploração da interpretabilidade das classificações utilizando a abordagem LIME e conceitos de preservação de espacialidade (Seção \ref{results:class:lime}).


\subsubsection{Diferença de conjuntos de dados}
\label{results:class:datasets}
A utilização de múltiplos conjuntos de dados foi fundamental para o presente estudo, uma vez que a diversidade de informações teve um impacto significativo na capacidade da rede VGG-16 em capturar detalhes e características. Esse comportamento está diretamente alinhado com a motivação subjacente ao uso das Redes Neurais Convolucionais (CNNs), como discutido no Capítulo \ref{cnn}. A Figura \ref{results:fig:datasets:0} ilustra a diferença de resolução entre amostras dos conjuntos de dados CIFAR 100 e \textit{Food}-101, proporcionando uma melhor compreensão das disparidades entre eles.

\begin{figure}[H]
    \centering
    \caption{Exemplo do conjunto de dados CIFAR 100 à esquerda e \textit{Food}-101 à direita, em escala real.}
    \label{results:fig:datasets:0}
    \includegraphics[width=1\textwidth]{recursos/imagens/results/dataset_diff.png}

    Fonte: do próprio autor.
\end{figure}

Adicionalmente, é relevante mencionar que em conjuntos de dados com amostras pequenas, como é o caso do CIFAR-100, a quantidade de informação a ser preservada é mínima. Isso pode explicar o desempenho inferior do método BPCAPooling em comparação com os métodos de \textit{pooling} tradicionais, como \textit{Max Pooling} e \textit{Avg Pooling}. Outra possível explicação para o resultado inferior do uso do conjunto de dados \textit{Food}-101 em relação ao CIFAR-100 é que, com o CIFAR-100 possuindo amostras de menor resolução, a variabilidade dos dados também é menor. Isso permite que o BPCAPooling tenha uma representação mais eficiente de blocos. No entanto, no conjunto de dados \textit{Food}-101, que apresenta uma variabilidade mais alta nas configurações de blocos, o BPCAPooling pode não preservar informações suficientes no mapa de características ao representar com o uso de um único componente.

Além disso, conforme discutido na Seção \ref{results:class}, ao analisar o processo de \textit{fine-tuning} utilizando o método BPCAPooling, destaca-se um comportamento notável no quarto bloco convolucional, onde ocorre uma tendência ascendente na acurácia e uma tendência de redução na \textit{loss} ao longo das épocas de treinamento e validação. Essa tendência sugere que características espaciais importantes provavelmente estão sendo capturadas e retidas no quarto bloco convolucional. É notável que o modelo não apresenta sinais de \textit{overfitting} nesse bloco, indicando que mais épocas poderiam ser empregadas nessa etapa do processo para explorar melhor essa tendência ascendente. Contudo, é crucial considerar que a condução de épocas adicionais demandaria recursos computacionais significativos, devido à complexidade do método e ao custo computacional associado.

A representação da acurácia e \textit{loss} para o conjunto de dados CIFAR 100 está ilustrada nas Figuras \ref{results:fig:datasets:1} e \ref{results:fig:datasets:2}, respectivamente, enquanto as Figuras \ref{results:fig:datasets:3} e \ref{results:fig:datasets:4} mostram a evolução da acurácia e \textit{loss} para o conjunto de dados \textit{Food}-101, todas referentes ao uso do método BPCAPooling.


\begin{figure}[H]
    \centering
    \caption{Evolução de Acurácia no conjunto de dados CIFAR 100.}
    \label{results:fig:datasets:1}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_wp_accuracy.png}
         \caption{Aquecimento.}
         \label{results:fig:datasets:1.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_accuracy1.png}
         \caption{Bloco 5.}
         \label{results:fig:datasets:1.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_accuracy2.png}
         \caption{Bloco 4.}
         \label{results:fig:datasets:1.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_accuracy3.png}
         \caption{Bloco 3.}
         \label{results:fig:datasets:1.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
 \end{figure}

\begin{figure}[H]
    \centering
    \caption{Evolução de \textit{Loss} no conjunto de dados CIFAR 100.}
    \label{results:fig:datasets:2}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_wp_loss.png}
         \caption{Aquecimento.}
         \label{results:fig:datasets:2.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_loss1.png}
         \caption{Bloco 5.}
         \label{results:fig:datasets:2.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_loss2.png}
         \caption{Bloco 4.}
         \label{results:fig:datasets:2.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/cifar_loss3.png}
         \caption{Bloco 3.}
         \label{results:fig:datasets:2.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
 \end{figure}


\begin{figure}[H]
    \centering
    \caption{Evolução de Acurácia no conjunto de dados \textit{Food}-101.}
    \label{results:fig:datasets:3}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_wp_accuracy.png}
         \caption{Aquecimento.}
         \label{results:fig:datasets:3.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_accuracy1.png}
         \caption{Bloco 5.}
         \label{results:fig:datasets:3.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_accuracy2.png}
         \caption{Bloco 4.}
         \label{results:fig:datasets:3.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_accuracy3.png}
         \caption{Bloco 3.}
         \label{results:fig:datasets:3.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
 \end{figure}

\begin{figure}[H]
    \centering
    \caption{Evolução da \textit{Loss} no conjunto de dados \textit{Food}-101.}
    \label{results:fig:datasets:4}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_wp_loss.png}
         \caption{Aquecimento.}
         \label{results:fig:datasets:4.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_loss1.png}
         \caption{Bloco 5.}
         \label{results:fig:datasets:4.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_loss2.png}
         \caption{Bloco 4.}
         \label{results:fig:datasets:4.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/food_loss3.png}
         \caption{Bloco 3.}
         \label{results:fig:datasets:4.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
 \end{figure}

Em suma, a diversidade dos conjuntos de dados utilizados neste estudo forneceu uma avaliação do método BPCAPooling, destacando pontos de atenção e a necessidade de otimizações específicas para diferentes cenários. As diferenças nos resultados reforçam a importância da seleção apropriada do conjunto de dados considerando suas características particulares.

\subsubsection{LIME e Preservação de Espacialidade}
\label{results:class:lime}
Em termos de preservação das informações espaciais entre as camadas de \textit{pooling}, o método BPCAPooling se destacou em relação a outros métodos quando analisado em camadas de \textit{pooling} de alto nível em ambos os conjuntos de dados (3ª camada).

No conjunto de dados CIFAR 100, é visível que as características geométricas das imagens são mantidas ao usar o BPCAPooling. Em contraste com os métodos convencionais, não se observam imagens completamente escurecidas ou com ruído nas camadas de mais baixo nível, como ilustrado na Figura \ref{results:fig:datasets:5} e ampliado na Figura \ref{results:fig:datasets:5v2}, indicado destaque em vermelho. Apesar do tamanho menor da imagem no conjunto CIFAR 100, resultando em mapas de características de dimensão $2 \times 2$ nas camadas posteriores, o que torna a preservação espacial um desafio, optou-se por manter a arquitetura VGG-16 original sem alterações estruturais, em vez de remover os blocos convolucionais ulteriores.

\begin{figure}[H]
    \centering
    \caption{Representação com primeira e segunda camada de \textit{pooling} aplicada no conjunto de dados CIFAR 100.}
    \label{results:fig:datasets:5}
    \includegraphics[width=1\textwidth]{recursos/imagens/results/cifar_blocks.png}

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Representação ampliada da Figura \ref{results:fig:datasets:5}.}
    \label{results:fig:datasets:5v2}
    \includegraphics[width=1\textwidth]{recursos/imagens/results/cifar_blocksv2.png}

    Fonte: do próprio autor.
\end{figure}


Ao analisar as camadas de \textit{pooling} aplicadas ao conjunto de dados \textit{Food}-101, representadas nas Figuras \ref{results:fig:datasets:max} e \ref{results:fig:datasets:bpca}, observa-se diferenças nas intensidades das saídas dessas camadas. As saídas resultantes do método \textit{Max Pooling} apresentam menor intensidade, enquanto as saídas do método BPCAPooling exibem maior intensidade, resultando em imagens com maior clareza e definição, principalmente de bordas.

\begin{figure}[p]
    \caption{Resultado visual de camadas de \textit{pooling} do conjunto \textit{Food}-101. Camadas com \textit{Max Pooling}.}
    \centering
    \label{results:fig:datasets:max}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/original.png}
         \caption{Imagem original.}
         \label{results:fig:datasets:max_original}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max1.png}
         \caption{Bloco 5.}
         \label{results:fig:datasets:max.1}
     \end{subfigure}%
     ~ 
 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max2.png}
         \caption{Bloco 4.}
         \label{results:fig:datasets:max.2}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max3.png}
         \caption{Bloco 3.}
         \label{results:fig:datasets:max.3}
     \end{subfigure}%
     ~ 
 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max4.png}
         \caption{Bloco 2.}
         \label{results:fig:datasets:max.4}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max5.png}
         \caption{Bloco 1.}
         \label{results:fig:datasets:max.5}
     \end{subfigure}%
 
     Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \caption{Resultado visual de camadas de \textit{pooling} do conjunto \textit{Food}-101. Camadas com BPCAPooling.}
    \centering
    \label{results:fig:datasets:bpca}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/original.png}
         \caption{Imagem original.}
         \label{results:fig:datasets:bpca_original}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca1.png}
         \caption{Bloco 5.}
         \label{results:fig:datasets:bpca.1}
     \end{subfigure}%
     ~ 
 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca2.png}
         \caption{Bloco 4.}
         \label{results:fig:datasets:bpca.2}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca3.png}
         \caption{Bloco 3.}
         \label{results:fig:datasets:bpca.3}
     \end{subfigure}%
     ~ 
 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca4.png}
         \caption{Bloco 2.}
         \label{results:fig:datasets:bpca.4}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca5.png}
         \caption{Bloco 1.}
         \label{results:fig:datasets:bpca.5}
     \end{subfigure}%
 
     Fonte: do próprio autor.
\end{figure}


Outro ponto é a discrepância nas últimas camadas de BPCAPooling, como mencionado anteriormente no contexto do conjunto de dados CIFAR 100. As saídas dessas camadas finais de BPCAPooling parecem conter ruídos visuais, enquanto as saídas das últimas camadas com \textit{Max Pooling} aparentam conter mais informações agregadas. Isso é evidenciado na Figura \ref{results:fig:datasets:7}, que mostra resultados com resolução superior a $2 \times 2$, devido à resolução maior das imagens de entrada.

\begin{figure}[H]
    \centering
   \caption{Visualização das últimas camadas de \textit{pooling} no conjunto \textit{Food}-101.}
    \label{results:fig:datasets:7}
    \begin{subfigure}[t]{0.85\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/block5_pool_4_max.png}
        \caption{Camada com \textit{Max Pooling}.}
        \label{results:fig:datasets:7.1}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.85\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/block5_pool_4_bpca.png}
        \caption{Camada com BPCAPooling.}
        \label{results:fig:datasets:7.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

No contexto das análises realizadas com LIME, é importante ressaltar um fator crucial para o desempenho dessa técnica: o tamanho da amostra de imagem. Ao considerar as imagens do conjunto de dados CIFAR 100, obter resultados satisfatórios foi desafiador devido ao pequeno tamanho de $32 \times 32$ \textit{pixels} de cada exemplo do conjunto de dados. Nessa escala, cada \textit{pixel} possui um peso significativo em comparação com a área total da imagem. Na Figura \ref{results:fig:datasets:8}, as contribuições positivas são representadas por \textit{pixels} verdes e as contribuições negativas por \textit{pixels} vermelhos para uma inferência de classe específica. Entretanto, como evidenciado na Figura, todos os \textit{pixels} influenciam positiva ou negativamente a classificação devido ao pequeno tamanho da imagem, não havendo distinções por região.

\begin{figure}[H]
    \centering
    \caption{Exemplo de imagens explicadas por LIME no conjunto de dados CIFAR 100.}
    \label{results:fig:datasets:8}
    \includegraphics[width=1\textwidth]{recursos/imagens/results/lime_explanations_cifar.png}

    Fonte: do próprio autor.
\end{figure}

Por outro lado, ao examinar as imagens relacionadas ao conjunto de dados \textit{Food}-101, é evidente que o LIME oferece mais \textit{insights} sobre as classificações realizadas. Como demonstrado na Figura \ref{results:fig:datasets:9}, apenas as regiões relevantes (positivamente ou negativamente) são destacadas, apresentando um tamanho de imagem apropriado, ao contrário do conjunto de dados CIFAR 100. Além disso, a análise dos resultados revela que, em alguns casos, a rede enfoca mais em embalagens, utensílios e louças, diminuindo a relevância das informações relacionadas à alimentação. Esta questão poderia ser abordada ao melhorar a estratégia de aquisição de dados, como ampliar as imagens ou aplicar técnicas de segmentação (por exemplo, \cite{rother2004grabcut}), garantindo que a comida ocupe a maior parte da área da imagem.

\begin{figure}[H]
    \centering
    \caption{Exemplo de imagens explicadas por LIME no conjunto de dados \textit{Food}-100.}
    \label{results:fig:datasets:9}
    \includegraphics[width=1\textwidth]{recursos/imagens/results/lime_explanations_food.png}

    Fonte: do próprio autor.
\end{figure}


\subsection{Resultados da Segmentação Semântica}
\label{results:semantic}
Em relação aos resultados da segmentação semântica, é relevante destacar que as discussões e descobertas abordadas na tarefa de classificação (Seção \ref{results:class}) foram consideradas como um primeiro passo rumo à implementação do método BPCA como camada de \textit{pooling} (BPCAPooling) na tarefa subsequente de segmentação semântica. Esta transição para uma nova tarefa demandaria validações finais para aprimorar o processo experimental específico para esse contexto.

É importante observar que, ao considerar as segmentações realizadas, os resultados obtidos com a aplicação do método BPCAPooling apresentaram similaridades em termos de valores quando comparados ao método tradicional \textit{Max Pooling} na arquitetura da U-Net. Essa comparação pode ser visualizada nas Tabelas \ref{results:semantic:tab:1} e \ref{results:semantic:tab:2}.

\begin{table}[H]
    \centering
    \caption{Resultados de U-Nets treinadas por 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} com base em acurácia.}
    \label{results:semantic:tab:1}
    \resizebox{1\textwidth}{!}{
        \begin{tabular}{l|l|l|l|l|l}
            \multicolumn{1}{c|}{\textbf{Método de \textit{Pooling}}} & \multicolumn{1}{c|}{\textbf{Tempo de Execução}}  & \multicolumn{2}{c|}{\textbf{Acurácia (\%)}}                                    & \multicolumn{2}{c}{\textbf{\textit{Loss}}}                                    \\
            \cline{3-6}
            \multicolumn{1}{c|}{}                                    & \multicolumn{1}{c|}{\textbf{(minutos)}}          & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}} & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c}{\textbf{Validação}} \\
            \hline
            BPCAPooling                                              &  252:82                                         &  87,982                               &  87,50                                  &  \textbf{0,5160}                     &  \textbf{0,7284}                        \\
            \textit{Max Pooling}                                     &  \textbf{96:98}                                 &  \textbf{89,381}                      &  \textbf{88,64}                         &  0,5484                              &  0,8109                                 \\
        \end{tabular}
    }

    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}

\begin{table}[H]
    \centering
    \caption{Resultados de U-Nets treinadas por 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} com base em mIoU.}
    \label{results:semantic:tab:2}
    \resizebox{1\textwidth}{!}{
        \begin{tabular}{l|l|l|l|l|l|l|l|l|l}
            \multicolumn{1}{c|}{\textbf{Método de \textit{Pooling}}} & \multicolumn{1}{c|}{\textbf{Tempo de Execução}}  & \multicolumn{2}{c|}{\textbf{Acurácia (\%)}}                                    & \multicolumn{2}{c|}{\textbf{\textit{Loss}}}                                    & \multicolumn{2}{c|}{\textbf{mIoU}}                                             & \multicolumn{2}{c}{\textbf{Dice}}                                              \\
            \cline{3-10}
            \multicolumn{1}{c|}{}                                    & \multicolumn{1}{c|}{\textbf{(minutos)}}          & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}} & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}}  & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}} & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c}{\textbf{Validação}}  \\
            \hline
            BPCAPooling                                              &  154:09                                          &  86,30                               &  86,77                                  &  0,5756                              &  \textbf{0,6659}                        & 0,3344                               & 0,3333                                  & \textbf{0,8892}                       & 0,8953                                  \\
            \textit{Max Pooling}                                     &  \textbf{57:23}                                  &  \textbf{88,750}                     &  \textbf{88,61}                         &  \textbf{0,4683}                     &  0,6668                                 & \textbf{0,3367}                      & \textbf{0,3367}                         & 0,8887                               & 0,8953                                   \\
        \end{tabular}
    }

    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}

Analisando as tabelas anteriores, observa-se que, embora as métricas adotadas para conduzir os experimentos sejam acurácia e mIoU, a \textit{loss} associada ao BPCAPooling foi menor nas etapas de validação, conforme evidenciado na Figuras \ref{results:fig:semantic:metrics1.2} e \ref{results:fig:semantic:metrics1.4}. Além disso, o método de \textit{pooling} se demonstrou ser igual ou superior aos resultados obtidos com o uso do BPCAPooling quando mensurado pela métrica Dice, apesar da diferença não ser significativa. Entretanto, é importante ressaltar que, quantitativamente, a métrica mIoU tende a penalizar mais instâncias únicas com classificações ruins do que a métrica Dice, mesmo quando ambas concordam que essa instância é ruim. Ademais, a métrica mIoU tende a agravar os erros, resultando em um efeito de \quotes{quadratura} em relação ao Dice. Como resultado, a métrica Dice parece medir algo mais próximo do desempenho médio, como evidenciado nas Figuras \ref{results:fig:semantic:metrics2.3} e \ref{results:fig:semantic:metrics3.3}, enquanto a mIoU mede algo mais próximo do pior caso de desempenho.

\begin{figure}[H]
    \centering
    \caption{Métricas de U-Nets com 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em acurácia.}
    \label{results:fig:semantic:metrics1}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max500_acc_accuracy.png}
         \caption{Acurácia do \textit{Max Pooling}.}
         \label{results:fig:semantic:metrics1.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max500_acc_loss.png}
         \caption{\textit{Loss} do \textit{Max Pooling}.}
         \label{results:fig:semantic:metrics1.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca500_acc_accuracy.png}
         \caption{Acurácia do BPCAPooling.}
         \label{results:fig:semantic:metrics1.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca500_acc_loss.png}
         \caption{\textit{Loss} do BPCAPooling.}
         \label{results:fig:semantic:metrics1.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Métricas de U-Net com BPCAPooling e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:metrics2}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unet500_miou_accuracy.png}
         \caption{Acurácia.}
         \label{results:fig:semantic:metrics2.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unet500_miou_loss.png}
         \caption{\textit{Loss}.}
         \label{results:fig:semantic:metrics2.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unet500_miou_dice_coefficient.png}
         \caption{Dice.}
         \label{results:fig:semantic:metrics2.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unet500_miou_mean_iou.png}
         \caption{mIoU.}
         \label{results:fig:semantic:metrics2.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Métricas de U-Net com \textit{Max Pooling} e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:metrics3}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unet500_miou_accuracy.png}
         \caption{Acurácia.}
         \label{results:fig:semantic:metrics3.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unet500_miou_loss.png}
         \caption{\textit{Loss}.}
         \label{results:fig:semantic:metrics3.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unet500_miou_dice_coefficient.png}
         \caption{Dice.}
         \label{results:fig:semantic:metrics3.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unet500_miou_mean_iou.png}
         \caption{mIoU.}
         \label{results:fig:semantic:metrics3.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
\end{figure}

Outro aspecto a se considerar ao analisar as Tabelas \ref{results:semantic:tab:1} e \ref{results:semantic:tab:2} é o tempo de execução durante os processos de treinamento e validação. Notavelmente, os tempos para o método \textit{Max Pooling} são significativamente mais rápidos quando comparado ao BPCAPooling, atribuídos à complexidade do método proposto discutida na Seção \ref{conclusion:future}. No entanto, é importante destacar que os modelos atingiram a convergência em um número próximo de épocas, os modelos baseados na métrica de acurácia convergiram em $168$ épocas para BPCAPooling e $172$ épocas para \textit{Max Pooling}. Enquanto, os modelos baseados na métrica mIoU convergiram em $102$ épocas para BPCAPooling e $101$ para \textit{Max Pooling}.

Por fim, ao considerar um nível de significância de $5\%$ para os modelos U-Nets treinados durante $500$ épocas, observa-se que não há diferença significativa nos campos de acurácia, tanto nos conjuntos de teste quanto nos de validação, apresentando p-valores de $0.1479$ e $0.2192$, respectivamente. No entanto, ao analisar os valores de mIoU, embora os p-valores sejam de $0.0678$ e $0.0110$ para teste e validação, respectivamente, indicando ausência de diferença significativa no primeiro caso e uma diferença no segundo caso (considerando um nível de significância de $5\%$), é importante ressaltar que visualmente é desafiador discernir tais diferenças, uma vez que a segmentação apresenta uma semelhança notável, sendo assim maiores detalhes sobre as diferenças serão relatados ainda nessa seção. Os resultados visuais podem ser observados nas Figuras \ref{results:fig:semantic:0} e \ref{results:fig:semantic:1}, correspondendo ao primeiro e segundo caso mencionados, respectivamente.

\begin{figure}[H]
    \centering
   \caption{Imagem de entrada, máscara e saída do modelo U-Net baseado em acurácia, respectivamente.}
    \label{results:fig:semantic:0}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{recursos/imagens/results/image_0_max_unet_500.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:semantic:0.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{recursos/imagens/results/image_0_bpca_unet_500.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:semantic:0.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}


\begin{figure}[H]
    \centering
   \caption{Imagem de entrada, máscara e saída do modelo U-Net baseado em mIoU, respectivamente.}
    \label{results:fig:semantic:1}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{recursos/imagens/results/image_0_max_unet_miou.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:semantic:1.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/image_0_bpca_unet_miou.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:semantic:1.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

Três representações das máscaras previstas sobrepondo a imagem de entrada são exibidas para cada um dos modelos nas Figuras \ref{results:fig:semantic:2}, \ref{results:fig:semantic:3}, \ref{results:fig:semantic:4} e \ref{results:fig:semantic:5}. Observa-se que a aplicação da métrica mIoU se mostra mais eficaz quando comparada à acurácia. Além disso, o método BPCAPooling enfatiza mais os contornos em comparação com o método \textit{Max Pooling}, que aparentemente enfatiza mais os \textit{pets}, tendo que para ambos os métodos o fundo possui a mesma eficácia de segmentação.

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net com \textit{Max Pooling} e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:2}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_miou_unet500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:2.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_miou_unet500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:2.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_miou_unet500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:2.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net com BPCAPooling e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:3}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_miou_unet500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:3.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_miou_unet500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:3.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_miou_unet500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:3.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net com \textit{Max Pooling} e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em acurácia.}
    \label{results:fig:semantic:4}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_acc_unet500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:4.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_acc_unet500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:4.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_acc_unet500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:4.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net com BPCAPooling e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em acurácia.}
    \label{results:fig:semantic:5}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_acc_unet500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:5.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_acc_unet500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:5.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_acc_unet500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:5.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

Os resultados obtidos com a arquitetura U-Net-\textit{Like} não apresentaram grandes diferenças quando comparados com os casos anteriores ou com a utilização do método \textit{Max Pooling}. No entanto, é importante ressaltar que, ao empregar a U-Net-\textit{Like}, os resultados do BPCAPooling mostraram-se inferiores em todos os aspectos, exceto nos valores de Dice na etapa de validação, como também ocorreu na arquitetura U-Net. Essa comparação é ilustrada nas Tabelas \ref{results:semantic:tab:3} e \ref{results:semantic:tab:4}.

\begin{table}[H]
    \centering
    \caption{Resultados de U-Net-\textit{Likes} treinadas por 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} com base em acurácia.}
    \label{results:semantic:tab:3}
    \resizebox{1\textwidth}{!}{
        \begin{tabular}{l|l|l|l|l|l}
            \multicolumn{1}{c|}{\textbf{Método de \textit{Pooling}}} & \multicolumn{1}{c|}{\textbf{Tempo de Execução}}  & \multicolumn{2}{c|}{\textbf{Acurácia (\%)}}                                    & \multicolumn{2}{c}{\textbf{\textit{Loss}}}                                    \\
            \cline{3-6}
            \multicolumn{1}{c|}{}                                    & \multicolumn{1}{c|}{\textbf{(minutos)}}          & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}} & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c}{\textbf{Validação}} \\
            \hline
            BPCAPooling                                              &  116:99                                         &  79,312                               &  78,61                                  &  0,7032                              &  0,8109                                \\
            \textit{Max Pooling}                                     &  \textbf{24:81}                                 &  \textbf{82,472}                      &  \textbf{81,84}                         &  \textbf{0,6144}                     &  \textbf{0,7936}                       \\
        \end{tabular}
    }

    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}

\begin{table}[H]
    \centering
    \caption{Resultados de U-Net-\textit{Likes} treinadas por 20 épocas no conjunto de dados \textit{Oxford-IIIT Pets} com base em mIoU.}
    \label{results:semantic:tab:4}
    \resizebox{1\textwidth}{!}{
        \begin{tabular}{l|l|l|l|l|l|l|l|l|l}
            \multicolumn{1}{c|}{\textbf{Método de \textit{Pooling}}} & \multicolumn{1}{c|}{\textbf{Tempo de Execução}}  & \multicolumn{2}{c|}{\textbf{Acurácia (\%)}}                                    & \multicolumn{2}{c|}{\textbf{\textit{Loss}}}                                    & \multicolumn{2}{c|}{\textbf{mIoU}}                                             & \multicolumn{2}{c}{\textbf{Dice}}                                               \\
            \cline{3-10}
            \multicolumn{1}{c|}{}                                    & \multicolumn{1}{c|}{\textbf{(minutos)}}          & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}} & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}}  & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c|}{\textbf{Validação}} & \multicolumn{1}{c|}{\textbf{Treino}} & \multicolumn{1}{c}{\textbf{Validação}}  \\
            \hline
            BPCAPooling                                              &  10:99                                           &  70,95                               &  71,55                                  &  0,7133                              &  0,6935                                 & 0,3086                               & 0,3102                                  & \textbf{0,8889}                               & 0,8970                                   \\
            \textit{Max Pooling}                                     &  \textbf{3:19}                                   &  \textbf{77,97}                      &  \textbf{78,19}                         &  \textbf{0,5571}                     &  \textbf{0,5508}                                 & \textbf{0,3164}                      & \textbf{0,3177}                         & 0,8892                                        & 0,8970                                   \\
        \end{tabular}
    }

    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}

Além da métrica Dice, vale ressaltar que o comportamento do tempo de execução é muito semelhante ao observado nos casos de uso das U-Nets, em que as abordagens com \textit{Max Pooling} demonstram um melhor desempenho. Contudo, ao comparar os tempos de execução da Tabela \ref{results:semantic:tab:3} com as Tabelas \ref{results:semantic:tab:1} e \ref{results:semantic:tab:2}, nota-se que o desempenho das U-Net-\textit{Like} é superior. Isso se deve à influência das estratégias de otimização, como normalização de \textit{batch}, convolução separável e \textit{upsampling}, que reduzem a quantidade de parâmetros em comparação com as U-Nets convencionais. No entanto, as comparações em relação aos valores de avaliação ainda se mostram superiores nas U-Nets convencionais, demonstrando que a robustez da arquitetura original tem seus benefícios.

A Figura \ref{results:fig:semantic:6} ilustra o progresso das métricas durante o processo de treinamento e validação dos modelos de U-Net-\textit{Like}, guiados pela métrica de acurácia. Já as Figuras \ref{results:fig:semantic:7} e \ref{results:fig:semantic:8} mostram os resultados dos modelos U-Net-\textit{Like} treinados por menos épocas, mas que apresentam métricas mais apropriadas para o contexto de segmentação semântica.

\begin{figure}[H]
    \centering
    \caption{Métricas de U-Net-\textit{Likes} com 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em acurácia.}
    \label{results:fig:semantic:6}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max500_ulike_acc_accuracy.png}
         \caption{Acurácia do \textit{Max Pooling}.}
         \label{results:fig:semantic:6.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max500_ulike_acc_loss.png}
         \caption{\textit{Loss} do \textit{Max Pooling}.}
         \label{results:fig:semantic:6.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca500_ulike_acc_accuracy.png}
         \caption{Acurácia do BPCAPooling.}
         \label{results:fig:semantic:6.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca500_ulike_acc_loss.png}
         \caption{\textit{Loss} do BPCAPooling.}
         \label{results:fig:semantic:6.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Métricas de U-Net-\textit{Likes} com BPCAPooling e 20 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:7}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unetlike20_miou_accuracy.png}
         \caption{Acurácia.}
         \label{results:fig:semantic:7.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unetlike20_miou_loss.png}
         \caption{\textit{Loss}.}
         \label{results:fig:semantic:7.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unetlike20_miou_dice_coefficient.png}
         \caption{Dice.}
         \label{results:fig:semantic:7.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_unetlike20_miou_mean_iou.png}
         \caption{mIoU.}
         \label{results:fig:semantic:7.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Métricas de U-Net-\textit{Likes} com \textit{Max Pooling} e 20 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:8}
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unetlike20_miou_accuracy.png}
         \caption{Acurácia.}
         \label{results:fig:semantic:8.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unetlike20_miou_loss.png}
         \caption{\textit{Loss}.}
         \label{results:fig:semantic:8.2}
     \end{subfigure}%
     ~ 
     
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unetlike20_miou_dice_coefficient.png}
         \caption{Dice.}
         \label{results:fig:semantic:8.3}
     \end{subfigure}
     ~
     \begin{subfigure}[t]{0.45\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_unetlike20_miou_mean_iou.png}
         \caption{mIoU.}
         \label{results:fig:semantic:8.4}
     \end{subfigure}
     
     Fonte: do próprio autor.
\end{figure}

Analisando essas tabelas por meio de testes estatísticos, observa-se uma diferença estatisticamente significativa para as métricas de acurácia e \textit{loss} nas fases de treinamento e validação das U-Net-\textit{Like} baseadas na acurácia, considerando um nível de significância de $5\%$. No entanto, essa diferença não é observada para as demais métricas, como Dice, acurácia de validação, Dice de validação, \textit{loss} de validação e mIoU de validação, apresentando os respectivos valores de p-valor de $0.7962$, $0.6730$, $0.2130$, $0.1175$ e $0.2198$, ainda mantendo o limiar de significância de $5\%$.

Em termos visuais, assim como constatado anteriormente com as U-Nets, além da análise das métricas, as imagens também indicam uma qualidade inferior na segmentação em comparação com os modelos U-Net. As Figuras \ref{results:fig:semantic:9} e \ref{results:fig:semantic:10} exibem as imagens de entrada, as máscaras e as máscaras geradas pelo modelo para um melhor entendimento visual.

\begin{figure}[H]
    \centering
   \caption{Imagem de entrada, máscara e saída do modelo U-Net-\textit{Like} baseado em acurácia, respectivamente.}
    \label{results:fig:semantic:9}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{recursos/imagens/results/image_0_max_unetlike_500.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:semantic:9.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{recursos/imagens/results/image_0_bpca_unetlike_500.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:semantic:9.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Imagem de entrada, máscara e saída do modelo U-Net-\textit{Like} baseado em mIoU, respectivamente.}
    \label{results:fig:semantic:10}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{recursos/imagens/results/image_0_max_unetlike_miou.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:semantic:10.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/image_0_bpca_unetlike_miou.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:semantic:10.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

Por fim, ao analisar as Figuras \ref{results:fig:semantic:11}, \ref{results:fig:semantic:12}, \ref{results:fig:semantic:13} e \ref{results:fig:semantic:14}, evidencia-se a sobreposição dos resultados do modelo nas imagens de entrada. Esta visualização sinaliza a necessidade de estender o número de épocas para os modelos de segmentação U-Net-\textit{Like} treinados por apenas 20 épocas. Apesar da diferença nas acurácias não exceder $8\%$, a análise visual sugere um potencial de melhoria substancial, indicando que o modelo possivelmente pode obter resultados mais robustos com um treinamento prolongado.

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net-\textit{Like} com \textit{Max Pooling} e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em acurácia.}
    \label{results:fig:semantic:11}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_acc_unetlike500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:11.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_acc_unetlike500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:11.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_acc_unetlike500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:11.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net-\textit{Like} com BPCAPooling e 500 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em acurácia.}
    \label{results:fig:semantic:12}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_acc_unetlike500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:12.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_acc_unetlike500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:12.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_acc_unetlike500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:12.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net-\textit{Like} com \textit{Max Pooling} e 20 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:13}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_miou_unetlike500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:13.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_miou_unetlike500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:13.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/max_miou_unetlike500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:13.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Exemplos segmentados a partir de U-Net-\textit{Like} com BPCAPooling e 20 épocas no conjunto de dados \textit{Oxford-IIIT Pets} baseada em mIoU.}
    \label{results:fig:semantic:14}
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_miou_unetlie500_image_0_overlayed_segmentation.png}
         \label{results:fig:semantic:14.1}
     \end{subfigure}%
     ~ 
     \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_miou_unetlie500_image_1_overlayed_segmentation.png}
         \label{results:fig:semantic:14.2}
     \end{subfigure}%
     ~ 
    \begin{subfigure}[t]{0.32\textwidth}
         \centering
         \includegraphics[width=1\linewidth]{recursos/imagens/results/bpca_miou_unetlie500_image_2_overlayed_segmentation.png}
         \label{results:fig:semantic:14.3}
     \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

Como discutido na Seção \ref{project:explain}, para realizar as análises de interpretabilidade nas segmentações semânticas, a ferramenta LIME não se mostrou adequada. Portanto, optou-se pelo uso da ferramenta Xplique, a qual oferece métodos de atribuição que permitem a visualização de pontos de destaque para a compreensão das segmentações, mapeamento das bordas das áreas de interesse ou bordas entre duas áreas distintas de interesse.

Neste estudo, as principais classes de interesse consistem nos animais de estimação, conforme proposto pelo conjunto de dados \textit{Oxford-IIIT Pets}. Para cada um dos modelos, foram aplicados dez métodos de atribuição destinados à tarefa de segmentação semântica. Isso visava identificar os pontos mais relevantes para a compreensão da qualidade da segmentação, por meio do mapa de calor gerado por cada um dos métodos, como representado na Figura \ref{project:fig:explain:xplique}. Os métodos específicos utilizados foram: \textit{Gradient Input}, \textit{Integrated Gradients}, \textit{Smooth Grad}, \textit{Var Grad}, \textit{Square Grad}, \textit{Occlusion}, \textit{Rise}, \textit{Sobol}, \textit{HSIC} e \textit{Saliency}.

Ao término da execução de cada um desses métodos nos modelos, foram gerados escores para avaliar a qualidade de cada método com base em três métricas de fidelidade. Estas incluem: \textit{Deletion}, que mede o quão bem uma explicação baseada no mapa de saliência localiza as características importantes; \textit{Insertion}, que avalia a capacidade de uma explicação baseada no mapa de saliência em identificar elementos mínimos necessários para as classificações da classe de saída do modelo; e \textit{MuFidelity}, que quantifica a correlação entre variáveis importantes definidas pelo método de explicação e a queda na pontuação do modelo quando essas variáveis são redefinidas para um estado inicial. É importante citar que quanto menor o escore na coluna de \textit{Deletion}, melhor se apresenta o método, todavia, quanto maior o escore nas colunas \textit{Insertion} e \textit{MuFidelity}, melhor o desempenho do método.

A seguir, serão apresentados os gráficos comparativos para cada um dos modelos em uma das três imagens testadas, aleatoriamente, juntamente com as saídas dos métodos de atribuição principais para cada uma das métricas de fidelidade.

Nos modelos U-Nets baseados na métrica de acurácia, os gráficos dos escores estão disponíveis na Figura \ref{results:fig:xai:1}. Observa-se, através desta visualização, que os destaques com o uso do método BPCAPooling foram para os métodos \textit{Integrated Gradients}, \textit{Occlusion} e \textit{Sobol}, conforme representado na Figura \ref{results:fig:xai:2}. Estes métodos se referem, respectivamente, às métricas \textit{Deletion}, \textit{MuFidelity} e \textit{Insertion}. Já para o método \textit{Max Pooling}, os resultados mais significativos, seguindo a mesma ordem, foram obtidos pelos métodos \textit{Smooth Grad}, \textit{Sobol} e, novamente, \textit{Sobol}, como evidenciado na Figura \ref{results:fig:xai:3}.

\begin{figure}[H]
    \centering
    \caption{Gráfico com os escores dos métodos de atribuição nas U-Nets baseada na acurácia.}
    \label{results:fig:xai:1}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{recursos/imagens/results/bpca500_acc_image_0_barplot.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:xai:1.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_acc_unet500_image_0_barplot.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:xai:1.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net com BPCAPooling baseada em acurácia para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:2}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/bpca_acc_unet500_image_0_IntegratedGradients.png}
        \caption{\textit{Integrated Gradients}.}
        \label{results:fig:xai:2.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_acc_unet500_image_0_Occlusion.png}
        \caption{\textit{Occlusion}.}
        \label{results:fig:xai:2.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_acc_unet500_image_0_SobolAttributionMethod.png}
        \caption{\textit{Sobol}.}
        \label{results:fig:xai:2.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net com \textit{Max Pooling} baseada em acurácia para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:3}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/max_acc_unet500_image_0_SmoothGrad.png}
        \caption{\textit{Smooth Grad}.}
        \label{results:fig:xai:3.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_acc_unet500_image_0_SobolAttributionMethod.png}
        \caption{\textit{Sobol}.}
        \label{results:fig:xai:3.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_acc_unet500_image_0_SobolAttributionMethod.png}
        \caption{\textit{Sobol}.}
        \label{results:fig:xai:3.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

É importante ressaltar que, nesse ponto, algumas observações se destacam: nos resultados do método \textit{Sobol} utilizando o BPCAPooling, notam-se pontos fora da região do animal de estimação considerado como mínimos para a classificação. Por outro lado, no método \textit{Sobol} empregado no \textit{Max Pooling}, as características internas do animal, como regiões dos olhos e peito, são apontadas como pontos mínimos de relevância.


Para a utilização do modelo U-Net com o BPCAPooling, baseado na métrica de mIoU, o gráfico dos escores está disponível na Figura \ref{results:fig:xai:4}. Nessa combinação, os métodos que se destacaram foram \textit{Gradient Input}, \textit{Sobol} e \textit{Occlusion}, conforme representado na Figura \ref{results:fig:xai:5}. Já para a utilização do \textit{Max Pooling}, os métodos mais relevantes foram \textit{Smooth Grad}, \textit{Sobol} e \textit{Squared Gradients}, representados na Figura \ref{results:fig:xai:6}.

\begin{figure}[H]
    \centering
    \caption{Gráfico com os escores dos métodos de atribuição na U-Nets baseadas em mIoU.}
    \label{results:fig:xai:4}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{recursos/imagens/results/bpca_miou_unet500_image_1_barplot.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:xai:4.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_miou_unet500_image_1_barplot.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:xai:4.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net com BPCAPooling baseada em mIoU para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:5}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/bpca_miou_unet500_image_1_GradientInput.png}
        \caption{\textit{Gradient Input}.}
        \label{results:fig:xai:5.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_miou_unet500_image_1_SobolAttributionMethod.png}
        \caption{\textit{Sobol}.}
        \label{results:fig:xai:5.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_miou_unet500_image_1_Occlusion.png}
        \caption{\textit{Occlusion}.}
        \label{results:fig:xai:5.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net com \textit{Max Pooling} baseada em mIoU para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:6}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/max_miou_unet500_image_image_1_SmoothGrad.png}
        \caption{\textit{Smooth Grad}.}
        \label{results:fig:xai:6.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_miou_unet500_image_image_1_SobolAttributionMethod.png}
        \caption{\textit{Sobol}.}
        \label{results:fig:xai:6.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_miou_unet500_image_image_1_SquareGrad.png}
        \caption{\textit{Squared Gradients}.}
        \label{results:fig:xai:6.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

Uma observação relevante para essa combinação de modelo é que, diferentemente do modelo anterior, o uso do BPCAPooling, ao empregar o método \textit{Occlusion} como métrica de \textit{Insertion}, selecionou corretamente as partes centrais do animal de estimação como pontos de foco. Por outro lado, a combinação com o \textit{Max Pooling} fez uma seleção adequada das bordas do animal, identificando-as como pontos importantes, particularmente com o método \textit{Smooth Grad} definido como \textit{Deletion}.

Ao analisar o desempenho das U-Net-\textit{Likes}, primeiramente com base na métrica de acurácia, os escores podem ser visualizados na Figura \ref{results:fig:xai:7}. Observa-se um destaque significativo para os métodos \textit{Rise}, \textit{Squared Gradients} e \textit{Integrated Gradients}, conforme representado na Figura \ref{results:fig:xai:8}, quando se utiliza o BPCAPooling. No entanto, ao utilizar o \textit{Max Pooling}, os destaques recaem duas vezes no método \textit{VarGrad} e, por fim, no \textit{Integrated Gradients}.

\begin{figure}[H]
    \centering
    \caption{Gráfico com os escores dos métodos de atribuição nas U-Net-\textit{Likes} baseada em acurácia.}
    \label{results:fig:xai:7}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{recursos/imagens/results/bpca_acc_unetlike500_image_2_barplot.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:xai:7.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_acc_unetlike500_image_2_barplot.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:xai:7.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net-\textit{Like} com BPCAPooling baseada em acurácia para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:8}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/bpca_acc_unetlike500_image_2_Rise.png}
        \caption{\textit{Rise}.}
        \label{results:fig:xai:8.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_acc_unetlike500_image_2_SquareGrad.png}
        \caption{\textit{Squared Gradients}.}
        \label{results:fig:xai:8.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_acc_unetlike500_image_2_IntegratedGradients.png}
        \caption{\textit{Integrated Gradients}.}
        \label{results:fig:xai:8.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net-\textit{Like} com \textit{Max Pooling} baseada em acurácia para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:9}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/max_acc_unetlike500_image_2_VarGrad.png}
        \caption{\textit{VarGrad}.}
        \label{results:fig:xai:9.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_acc_unetlike500_image_2_VarGrad.png}
        \caption{\textit{VarGrad}.}
        \label{results:fig:xai:9.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_acc_unetlike500_image_2_IntegratedGradients.png}
        \caption{\textit{Integrated Gradients}.}
        \label{results:fig:xai:9.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

Nessa análise das U-Net-\textit{Likes}, os resultados revelaram más adaptações de segmentação para ambas as arquiteturas. Notavelmente, ao utilizar o BPCAPooling, a segmentação não corresponde à forma real do gato na amostra, evidenciando uma correlação inadequada entre um subconjunto aleatório de \textit{pixels} e a pontuação de atribuição, especialmente com a métrica \textit{Squared Gradients}, que se destacou como a melhor para \textit{Mu Fidelity}. Além disso, ao empregar o \textit{Max Pooling}, o método \textit{VarGrad} não selecionou uma grande parte do animal de interesse, demonstrando falhas na identificação das partes importantes (\textit{Deletion}).

Na análise da arquitetura U-Net-\textit{Like}, quando a métrica principal utilizada é a mIoU, observa-se uma distribuição mais ampla dos mapas de calor ao empregar ambos os métodos de \textit{pooling}, particularmente ao visualizar a métrica \textit{Mu Fidelity} em comparação com os métodos \textit{Rise} e \textit{Occlusion}. O \textit{ranking} das métricas para ambas as estratégias de \textit{pooling} é apresentado na Figura \ref{results:fig:xai:10}. Notavelmente, para o BPCAPooling, os métodos de destaque são \textit{Integrated Gradients}, \textit{Occlusion} e novamente \textit{Integrated Gradients}. Por outro lado, para o método \textit{Max Pooling}, \textit{Integrated Gradients} se destaca duas vezes, juntamente com o método \textit{Rise}.

\begin{figure}[H]
    \centering
    \caption{Gráfico com os escores dos métodos de atribuição nas U-Net-\textit{Likes} baseada em mIoU.}
    \label{results:fig:xai:10}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=1\textwidth]{recursos/imagens/results/bpca_miou_unetlie20_image_2_barplot.png}
        \caption{Modelo com BPCAPooling.}
        \label{results:fig:xai:10.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{1\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_unetlike20_miou_image_2_barplot.png}
        \caption{Modelo com \textit{Max Pooling}.}
        \label{results:fig:xai:10.2}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net-\textit{Like} com BPCAPooling baseada em mIoU para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:11}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/bpca_miou_unetlie20_image_2_IntegratedGradients.png}
        \caption{\textit{Integrated Gradients}.}
        \label{results:fig:xai:11.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_miou_unetlie20_image_2_Occlusion.png}
        \caption{\textit{Occlusion}.}
        \label{results:fig:xai:11.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/bpca_miou_unetlie20_image_2_IntegratedGradients.png}
        \caption{\textit{Integrated Gradients}.}
        \label{results:fig:xai:11.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
   \caption{Métodos de atribuição destaque na U-Net-\textit{Like} com \textit{Max Pooling} baseada em mIoU para \textit{Deletion}, \textit{Mu Fidelity} e \textit{Insertion}, respectivamente.}
    \label{results:fig:xai:12}
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{recursos/imagens/results/max_unetlike20_image_2_IntegratedGradients.png}
        \caption{\textit{Integrated Gradients}.}
        \label{results:fig:xai:12.1}
    \end{subfigure}%
    ~
    
    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_unetlike20_image_2_Rise.png}
        \caption{\textit{Rise}.}
        \label{results:fig:xai:12.2}
    \end{subfigure}%
    ~

    \begin{subfigure}[t]{0.9\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{recursos/imagens/results/max_unetlike20_image_2_IntegratedGradients.png}
        \caption{\textit{Integrated Gradients}.}
        \label{results:fig:xai:12.3}
    \end{subfigure}%

    Fonte: do próprio autor.
\end{figure}

Além disso, iniciou-se o desenvolvimento do método BPCAUnpooling, disponível no repositório do projeto \footnote{Repositório Github do projeto - \url{https://github.com/Lucs1590/USeS-BPCA}}, mas a implementação com o \textit{framework} atual representou uma barreira como será comentado na Seção \ref{conclusion:future}. Esse método seria uma abordagem alternativa de \textit{upsampling}, contrapartida ao BPCAPooling, revertendo o processo proposto por este último, preservando também a informação espacial com a consideração do contexto global no processo de reconstrução realizado pelas U-Nets e similares, como ilustrado na Figura \ref{results:fig:future:0}.

\begin{figure}[H]
    \centering
    \caption{Processo de redução e reconstrução de dimensionalidade com BPCAPooling e BPCAUnpooling, respectivamente.}
    \label{results:fig:future:0}
    \includegraphics[width=1\textwidth]{recursos/imagens/results/bpca_unpooling.png}

    Fonte: do próprio autor.
\end{figure}

A técnica BPCAUnpooling, em contraste com o procedimento BPCAPooling, requisita a utilização de camadas densamente conectadas para obter um efeito similar ao oferecido por camadas convolucionais transpostas. A operação deste método é expressa na Equação \ref{results:eq:bpca_unpooling}, nela $\boldsymbol{X'}_{i,j,k}$ simboliza o mapa de características resultante, com suas dimensões correspondendo, respectivamente, à altura ($i$), largura ($j$) e canais ($k$).

\begin{equation}
    \label{results:eq:bpca_unpooling}
    \begin{split}
        \boldsymbol{X'}_{i,j,k} &= \text{BPCAUnpooling}(\boldsymbol{Y}_{i',j',k'}) \\
                  &= \text{reshape}\left(U \cdot \left(\text{\textit{reshape}}(S) \cdot \text{Dense}\left(\text{pad}(\boldsymbol{Y})\right)\right)\right) \cdot {\boldsymbol{\sigma}} + {\boldsymbol{\mu}}.
    \end{split}
\end{equation}

A equação expressa o processo de restauração da dimensionalidade pela aplicação do método BPCAUnpooling. Este processo envolve operações de preenchimento, remodelagem e reconstrução dos dados desagrupados com base na decomposição PCA. Na equação, o operador $\text{BPCAUnpooling}(\boldsymbol{Y}_{i',j',k'})$ retrata a execução do procedimento BPCAUnpooling ao mapa de características de entrada $\boldsymbol{Y}$.

A função $pad(\boldsymbol{Y})$ preenche o mapa de características de entrada $\boldsymbol{Y}$ com zeros, adaptando o tamanho para a subsequente atividade de \textit{unpooling}. O termo matemático $\text{Dense}(\text{pad}(\boldsymbol{Y}))$ é empregado na aprendizagem dos componentes decorrentes da PCA, por meio da camada densa com função de ativação.

A função $\text{\textit{reshape}}$ reorganiza seus argumentos para a estrutura adequada, onde $S$ simboliza os valores singulares oriundos da decomposição PCA em alinhamento com os componentes da PCA. A expressão $U \cdot (\text{\textit{reshape}}(S) \cdot \text{Dense}(\text{pad}(\boldsymbol{Y})))$ reconduz os dados desagrupados com o auxílio dos componentes e valores singulares fornecidos pela PCA.

Finalmente, a operação de multiplicação pelo desvio padrão $\boldsymbol{\sigma}$ e acréscimo da média $\boldsymbol{\mu}$ refaz a normalização inicialmente feita antes da transformação PCA.

No contexto desta equação, $U$ denota a matriz de componentes principais adquirida através da fórmula BPCAPooling, responsável por codificar a estrutura intrínseca dos dados. Esta matriz direciona a reestruturação dos dados para a dimensionalidade original.

\subsection{Considerações Finais do Capítulo}
\label{result:final}
Neste capítulo, foram apresentados os resultados dos experimentos realizados, abordando tanto o processo de classificação (Seção \ref{results:class}) quanto os passos em direção ao objetivo final de empregar o BPCAPooling como uma proposta de camada de \textit{pooling} para segmentações semânticas, como explorado e detalhado na Seção \ref{results:semantic}.
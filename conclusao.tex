\newpage
\clearpage
\section{Conclusões}
\label{conclusion}
As técnicas de segmentação representam uma ferramenta valiosa para a identificação de regiões de interesse em imagens, abordando desde situações mais simples, abordadas pelas técnicas de segmentação tradicionais (Capítulo \ref{segment}), até cenários mais complexos, resolvidos pela segmentação semântica (Capítulo \ref{semantic}). Este último tipo de segmentação, em particular, apresenta semelhanças com a compreensão humana de cenários \citep{Mohan2020}, uma vez que classifica cada \textit{pixel} em uma cena, atribuindo-os a diversas classes. Tal capacidade só foi alcançada graças à evolução das arquiteturas de redes neurais profundas (Capítulo \ref{cnn}), que apresentam habilidades melhoradas de aprendizado e adaptação em resposta aos problemas fornecidos.

Em uma análise mais específica, focada no campo do aprendizado de imagens, as redes neurais convolucionais ganharam destaque (Capítulo \ref{cnn}). Esta evolução entre as redes neurais profundas, as convolucionais e a segmentação semântica direcionou o estudo para o teste de um método de \textit{pooling}, introduzido no contexto das CNNs, que preservasse a espacialidade das amostras, mantendo seus valores fundamentais, como explorado no Capítulo \ref{project}. O desenvolvimento desse método respondeu à primeira questão levantada nos objetivos deste trabalho, delineados na introdução (Capítulo \ref{intro}).

A aplicação do método \textit{Block-based Principal Component Analysis Pooling}, ou BPCAPooling, acompanhou a evolução das redes, iniciando sua aplicação em uma arquitetura comumente utilizada para as CNNs, a VGG-16. O objetivo era coletar insumos e avaliar a sua aplicabilidade como substituto dos métodos convencionais. Os resultados e discussões desses experimentos, detalhados no Capítulo \ref{results}, revelaram que os métodos convencionais - \textit{Max Pooling} e \textit{Avg Pooling} - ainda são superiores nos dois conjuntos de dados testados em problemas de classificação de imagens.

O melhor modelo utilizando \textit{Max Pooling} alcançou uma acurácia de $46,071\%$ e uma \textit{loss} de $1,4862$, no primeiro conjunto de dados, enquanto obteve uma acurácia de $50,080\%$ e uma \textit{loss} de $2,3745$ no segundo conjunto. Já o uso do BPCAPooling resultou em apenas $17,543\%$ de acurácia e $3,5121\%$ de \textit{loss} para o primeiro conjunto, e $4,4130\%$ de acurácia e $4,4404$ de \textit{loss} para o segundo conjunto. Portanto, os resultados indicam que o método desenvolvido não é recomendado como uma alternativa viável para substituir os métodos convencionais até o momento.

Apesar dos valores de acurácia e \textit{loss} relativamente baixos, o método apresentou diferenças visuais consideráveis em relação ao método tradicional. Essas diferenças foram evidentes ao utilizar ferramentas de explicabilidade de modelos e ao examinar características das saídas das redes, conforme mencionado na Seção \ref{results:class:datasets}.

No contexto das segmentações semânticas, os resultados obtidos (Capítulo \ref{results}) revelaram comportamento diferente dos casos de classificação ao aplicar o método proposto nas arquiteturas. Os modelos U-Net com o método proposto apresentaram uma mIoU de $0,3333$, acurácia de $86,77\%$ e uma \textit{loss} de $0,6659$, enquanto o modelo com uso de \textit{Max Pooling} obteve uma mIoU de $0,3367$ e acurácia de $88,61\%$, mas com uma \textit{loss} ligeiramente superior ($0,6668$). No entanto, todos os resultados mostram diferenças mínimas tanto em métricas quanto em qualidade visual das segmentações, sugerindo o BPCAPooling como uma alternativa válida ao método convencional, não fosse pela complexidade de código agregada, o que aumenta significativamente o tempo de execução durante as fases de treinamento e validação. Entretanto, este estudo abre uma possibilidade para que métodos tradicionais de extração de atributos e \textit{manifold learning} possam ser investigados como uma camada de \textit{pooling}, ou ainda, uma combinação de \textit{poolings}.


\subsection{Trabalhos Futuros}
\label{conclusion:future}
Para futuros desenvolvimentos, sugere-se: 1) a otimização do código desenvolvido, considerando a troca de \textit{frameworks}, visando a redução da complexidade do código; 2) testes em conjuntos de dados adicionais apropriados para a tarefa de segmentação semântica; 3) o desenvolvimento do método BPCAUnpooling para preservar a espacialidade das amostras na fase de decodificação das U-Nets; e 4) avaliar o uso da técnica BPCAPooling em outras tarefas de processamento de imagens, como para filtragem de ruído, considerando que as redes neurais profundas normalmente eliminam a camada de \textit{Max Pooling} para essa tarefa, visto que esse método acaba amplificando o ruído \citep{zhang2017beyond}. Além disso, ainda nessa seção, serão discutidos detalhes que podem contribuir para trabalhos futuros.

Como mencionado na Seção \ref{project:transf}, os experimentos de classificação empregaram os princípios de transferência de aprendizado, o que comumente oferece vantagens devido ao reaproveitamento de pesos de arquiteturas treinadas em grandes conjuntos de dados \citep{Pan2010}. No entanto, embora as camadas de \textit{pooling} não tenham parâmetros treináveis diretamente afetados pela retropropagação, elas influenciam diretamente as camadas de convolução subsequentes. Isso levanta a questão: \quotes{Será que o uso de transferência de aprendizado realmente contribuiu para a aplicação do método BPCAPooling nos experimentos realizados?} Uma vez que as camadas da rede passam a ficar com os pesos aquecidos, mas com o viés da utilização de um redutor de dimensionalidade que não olha para a informação espacial de um modo global, mas sim local, como é o caso do \textit{Max Pooling} e \textit{Avg Pooling}.

Além disso, outra questão pendente diz respeito a quais camadas precisam ser descongeladas para obter os melhores resultados possíveis com o método, como comentado na Seção \ref{results:class:datasets}, que demonstra maior progresso no quarto bloco convolucional.

Vale citar que a complexidade do método proposto é uma limitação. Um teste realizado com a arquitetura EfficientNetB0 \citep{Tan2019Efficientnet:Networks}, que possui $17$ camadas de \textit{pooling}, substituindo os métodos convencionais por BPCAPooling resultou em um tempo estimado de treinamento da fase de aquecimento de aproximadamente \textit{2.100} horas, de acordo com os padrões de desempenho comentados na Seção \ref{results:class}.

Para futuros trabalhos que visam aplicar o método BPCAPooling como camada de \textit{pooling} para arquiteturas de classificação, sugere-se a não utilização de transferência de aprendizado para o método, mas sim a realização de fases de treinamento e validação mais extensas, além do uso de conjuntos de dados equivalentes ao ImageNet, o que é um desafio devido às necessidades de \textit{hardware} que surgiriam. Uma sugestão adicional seria propor alternativas para otimizar a complexidade do código associado ao método BPCAPooling. Por fim, uma terceira ideia para trabalhos futuros, que também exigiria considerações sobre o \textit{hardware} necessário para os experimentos, seria a aplicação de mais épocas no descongelamento de determinados blocos convolucionais durante o processo de \textit{fine-tuning}, visando permitir a exploração mais profunda dos mapas de características e potencializar os aspectos de preservação espacial.

Um dos grandes desafios encontrados residiu na combinação dos \textit{frameworks} Tensorflow e Keras. Dado que a abordagem proposta consistia no desenvolvimento de uma camada personalizada de \textit{pooling}, erros de desenvolvimento eram comuns, afetando significativamente o tempo de implementação e outros aspectos mencionados nesta seção. Portanto, uma proposta para futuros trabalhos seria a exploração de diferentes \textit{frameworks}, como PyTorch \citep{Paszke2017AutomaticPyTorch}. Além de potencialmente melhorar o desempenho do método, conforme discutido anteriormente.

A dificuldade enfrentada com os \textit{frameworks} também prejudicou a aplicação do método em mais de um conjunto de dados para a tarefa de segmentação semântica. Uma excelente proposta futura seria estender os testes para um segundo conjunto de dados, preferencialmente com múltiplos objetos de interesse em cada exemplo. Conjuntos como \textit{Cityscape} \citep{Cordts2016} e \textit{Lost and Found} \citep{Pinggera2016LostVehicles} oferecem condições ideais para avaliar as capacidades de preservação de espacialidade do BPCAPooling em cenários mais complexos.

Um dos aspectos a serem explorados em pesquisas futuras diz respeito à análise da distribuição de energia dos componentes principais em relação aos autovalores. Em outras palavras, considerando que componentes principais com valores maiores indicam maior importância, seria interessante avaliar o quanto de informação está sendo preservado. Em alguns casos, pode ser vantajoso reorganizar e subdividir a informação em múltiplos componentes, garantindo assim que a quantidade de informação preservada seja significativa e relevante para a aplicação em questão.


\subsection{Considerações Finais do Capítulo}
\label{conclusion:final}
Vale citar que a partir desse trabalho foi possível submeter um artigo intitulado \textit{Exploring BPCA Pooling Layer in VGG-16 Network: A Comparative Study with Conventional Pooling Methods} na SIBGRAPI – \textit{Conference on Graphics, Patterns and Images}, tendo todo o código utilizado documentado no Github \footnote{Repositório Github do trabalho da conferência - \url{https://github.com/Lucs1590/vgg_bpca}}, alvejando aumentar o nível de contribuição com a comunidade científica.

Por fim, todo o código fonte utilizado neste trabalho está documentado e disponível como \textit{open-source}\footnote{Repositório Github do projeto - \url{https://github.com/Lucs1590/USeS-BPCA}}, buscando fomentar contribuições e incentivar a comunidade científica a avançar no tema abordado, facilitando futuras pesquisas nesta área a partir de um ponto inicial avançado e com algumas dificuldades mitigadas.

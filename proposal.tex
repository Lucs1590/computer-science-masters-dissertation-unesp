\newpage
\clearpage

\section{Proposta de Segmentação Panóptica em Componentes Visuais}
\label{proposal:proposal}

Considerando as segmentações modernas citadas nos Capítulos \ref{semantic:semantic}, \ref{instance:instance} e \ref{panoptic:panoptic}, fica claro que a segmentação panóptica é nomeada como a que possui maior riqueza de detalhes, de modo a ter uma compreensão mais clara das cenas, todavia considerando os problemas discorridos no Capítulo \ref{panoptic:panoptic}, bem como na Seção \ref{panoptic:conclusion}, estudos vêm sendo desenvolvidos para solucionar esses obstáculos.

\begin{sloppypar}
Dentre os estudos desenvolvidos, cita-se o de \textit{Part-Aware Panoptic Segmentation} \cite{DeGeus2021} com as propostas de trazer uma visão holística maior para as cenas e unir tarefas de \textit{scene parsing} e \textit{part parsing}, dispondo-se, indiretamente, também a trabalhar com objetos de pequena escala, o que é um problema para uma rede comum de segmentação panóptica, como a desenvolvida por \cite{Kirillov2019a}. A comparação, bem como demonstração de detalhes em relação a segmentação panóptica comum pode ser observada na Figura \ref{proposal:proposal:fig:4}.
\end{sloppypar}

\begin{figure}[H]
   \caption{Segmentação Panóptica e \textit{Part-Aware}.}
   \centering
   \label{proposal:proposal:fig:4}
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[height=1.25in]{recursos/imagens/proposal/pano_vs.png}
        \caption{Segmentação panóptica comum.}
        \label{proposal:proposal:fig:4.1}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[height=1.25in]{recursos/imagens/proposal/part_pano_vs.png}
        \caption{Segmentação com \textit{part-aware}.}
        \label{proposal:proposal:fig:4.2}
    \end{subfigure}%

    Fonte: retirado e adaptado de \cite{DeGeus2021}.
\end{figure}

Dentre as áreas com oportunidades para o desenvolvimento e aplicação dessa técnica, a qual ainda não fora explorada, cita-se a área odontológica que, como citado na Introdução (Capítulo \ref{intro:intro}), possibilita desafios com a meta de descrever o que há na boca a partir de fotografias orais, o que pode ser explorado por meio de um \textit{framework} de segmentação panóptica.

Sendo assim, este trabalho tem como objetivo aplicar técnicas de segmentação panóptica em componentes visuais odontológicos de modo a obter as segmentações organizadas hierarquicamente, ou seja, com os segmentos de cada pixel nas cenas e suas partes, o que é exemplificado por meio da Figura \ref{proposal:proposal:fig:3}. Além disso, tem uma nova proposta de camada de \textit{pooling} nos modelos base, com o intuito de buscar resultado relevantes no que se refere às validações de segmentação panóptica.

\begin{figure}[H]
    \centering
    \caption{Exemplo de aplicação de \textit{Part-Aware Panoptic Segmentation}. Linhas contendo a imagem de entrada, valor de referencia e segmentação realizada com o método \textit{part-aware}, respectivamente, de cima para baixo.}
    \includegraphics[width=1\linewidth]{recursos/imagens/proposal/part-aware-example.png}
    \label{proposal:proposal:fig:3}
    Fonte: \cite{DeGeus2021}.
\end{figure}

Em resumo, dentre as perspectivas de contribuição deste trabalho, lista-se:

\begin{enumerate}[I]
  \item A utilização da segmentação panóptica hierárquica para a segmentação de componentes visuais na área odontológica;
  \item A disponibilização de biblioteca de código com a finalidade de dar suporte aos trabalhos na área de \textit{part-aware panoptic segmentation}.
  \item A avaliação e adaptação (caso necessário) de uma ferramenta que auxilie a anotação de imagens com técnicas de segmentação;
  \item A aplicação da técnica \textit{block-based pca} \cite{Salvadeo2011} (será explicado na Seção \ref{proposal:pcapooling}) como camada de \textit{pooling} dos modelos base para a segmentação panóptica.
\end{enumerate}

As demais seções desse capítulo estão organizadas de seguinte modo: a Seção \ref{proposal:matmet} descreve sobre os materiais e métodos utilizados nos experimentos, a Seção \ref{proposal:methodology} descreve a metodologia utilizada em alguns dos experimentos propostos, a Seção \ref{proposal:revision} demonstra detalhamentos sobre a revisão de literatura em relação ao tema, a Seção \ref{proposal:cron} apresenta um cronograma das atividades neste trabalho, e, finalmente, a Seção \ref{proposal:expres} demonstra alguns resultados esperados no decorrer do andamento do presente trabalho.


\subsection{Materiais e Métodos}
\label{proposal:matmet}
Nesta Seção, serão discorridos os detalhes sobre as tecnologias que serão utilizadas para o desenvolvimento de um modelo de segmentação panóptica que segmenta componentes visuais (Seção \ref{proposal:tec}), as técnicas e métodos escolhidos para serem utilizados nos experimentos (Seção \ref{proposal:method}) e, por fim, sobre os conjuntos de dados selecionados para cumprirem com o objetivo da segmentação (Seção \ref{proposal:dataset}).


\subsubsection{Tecnologias}
\label{proposal:tec}
Dentre as tecnologias planejadas para o desenvolvimento do presente trabalho, vale citar que destaca-se o uso da linguagem de programação interpretada e de alto nível, \textit{Python}, sendo essa uma linguagem vantajosa por ser popularmente conhecida no meio cientifico, com uma ampla comunidade e com  bibliotecas dispostas para facilitar o desenvolvimento de soluções \cite{Millman2011PythonEngineers}.

Já em relação às bibliotecas planejadas ao projeto, destacam-se aquelas cujo desenvolvimento é amplamente utilizado para o auxilio de projetos de visão computacional, aprendizado de máquina e redes neurais, das quais cita-se: \textit{PyTorch}, \textit{Keras}, \textit{TensorFlow}, \textit{OpenCV}, \textit{Numpy}, \textit{Pandas}, entre outras, dando destaque para a biblioteca \textit{Detectron2} \cite{detectron2} que já possui algumas funções especializadas para o trabalho com segmentações, incluindo redes de segmentação panóptica.

Por fim, em relação aos métodos desenvolvidos para cumprir com os objetivos do presente trabalho, no que lhes concerne, de realizar a segmentação de componentes visuais, declara-se que serão disponibilizado em forma de biblioteca por meio do \textit{Github} do autor\footnote{Perfil \textit{Github} do autor – \url{https://github.com/Lucs1590}}, segundo os preceitos a licença Apache v2.0 \cite{Licenses}, com o intuito de contribuir com o crescimento de futuros pesquisadores, além de possibilitar futuras melhorias da aréa de segmentação com uso de segmentação hierárquica.


\subsubsection{Métodos}
\label{proposal:method}
Dentre os métodos disponíveis para realizar a tarefa de segmentação panóptica de componentes visuais, destaca-se que serão realizados testes a partir dos modelos disponibilizados pela biblioteca \textit{Detectron2} \cite{detectron2}, seguindo também a formatação inicial proposta por Kirillov \textit{et al.} \cite{Kirillov2019a}, a qual era composta por um modelo de Mask R-CNN (Seção \ref{instance:mask}) para realizar a parte de segmentação de instâncias e o modelo de FCN (Seção \ref{semantic:FCN}) para realizar a segmentação semântica.

Todavia, haja vista o resultado esperado nesse trabalho, vide a Seção \ref{proposal:expres}, para as tarefas de segmentação panóptica com o uso de partes, diferente das abordagens de estruturas que possuem apenas as tarefas de segmentações de instâncias e semântica, seja de modo compartilhado, unificado, com conexões ou cascata, como demonstradas na Figura \ref{proposal:method:fig:1}, a segmentação de partes cientes necessita, também, de uma parte voltada para a segmentação das partes de objetos classificados como \textit{thing} ou \textit{stuff}, como demonstrado na Figura \ref{proposal:method:fig:2}, a qual representa uma estrutura voltada para a segmentação panóptica de modo unificado (segmentação semântica e de instância) e outra para a segmentação de partes cientes. Sendo assim, também será testada a estrutura desenhada por de Geus \textit{et al.} \cite{DeGeus2021}, a qual é composta por um modelo de segmentação panóptica (DLv3-ResNeSt269 \& DetectoRS) juntamente com um modelo responsável por realizar uma segmentação de partes (BSANet).

\begin{figure}[H]
    \centering
    \caption{Metodologias de rede para segmentação panóptica.}
    \includegraphics[width=1\textwidth]{recursos/imagens/proposal/model_methodologies.png}
    \label{proposal:method:fig:1}

    Fonte: retirado e adaptado de \cite{Elharrouss2021}.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Estrutura exemplificando metodologia para segmentação \textit{Part-Aware}.}
    \includegraphics[width=4in]{recursos/imagens/proposal/estrutura.png}
    \label{proposal:method:fig:2}

    Fonte: do próprio autor.
\end{figure}


\subsubsection{Conjuntos de Dados}
\label{proposal:dataset}
Em relação ao conjunto de dados, por esse trabalho fazer uso da segmentação \textit{Part-Aware Panoptic Segmentation} proposta em \cite{DeGeus2021}, sendo que esta é uma nova abordagem, vale dizer que a quantidade de conjuntos de dados ainda é escassa, principalmente quando se trata de trabalhos voltados para uma área em específico, como a odontológica.

Todavia, no presente trabalho serão utilizados tanto conjuntos de dados que são mais generalistas, mas são voltados para a segmentação panóptica, quanto conjuntos de dados voltados para a parte odontológica, os quais precisarão ser anotados de modo a estarem adaptados para o seu uso em bases de treino e teste.

Quanto aos conjuntos de dados mais generalistas vale dizer que há algumas estratégias e justificativas para o seu uso, as quais serão descritas na Seção \ref{proposal:transf}, entretanto, dentre os conjuntos de dados escolhidos, destacam-se PASCAL \textit{Panoptic Parts} e \textit{Cityscapes Panoptic Parts}, sendo que os estes foram desenvolvidos pelos autores que abrolharam a segmentação panóptica com uso da técnica \textit{Part-Aware} \cite{DeGeus2021}.

O conteúdo dos conjuntos PASCAL \textit{Panoptic Parts} e \textit{Cityscapes Panoptic Parts} foram criados a partir dos conjuntos de dados \cite{everingham2010pascal} e \cite{Cordts2016}, sendo que o conteúdo do primeiro está voltado para pessoas, animais, veículos e cenas em locais fechados, quando o segundo conta com cenas de cidades, respectivamente, os quais são exemplificados na Figura \ref{proposal:dataset:fig:1}.

\begin{figure}[H]
   \caption{Imagens originais e anotadas dos \textit{datasets} para \textit{Part-Aware Panoptic Segmentation}.}
   \centering
   \label{proposal:dataset:fig:1}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[height=2.5in]{recursos/imagens/proposal/city.png}
        \caption{Imagem original e anotada do \textit{Cityscapes Panoptic Parts}, respectivamente.}
        \label{proposal:dataset:fig:1.1}
    \end{subfigure}%
    ~ 
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[height=2.5in]{recursos/imagens/proposal/pascal.png}
        \caption{Imagem original e anotada do PASCAL \textit{Panoptic Parts}, respectivamente.}
        \label{proposal:dataset:fig:1.2}
    \end{subfigure}%

    Fonte: retirado e adaptado de \cite{Lin2016}.
\end{figure}


Os conjuntos criados por \cite{DeGeus2021}, os quais contemplam segmentação \textit{Part-Aware}, quando relacionado ao \textit{Cityscape Panoptic Parts}, vale dizer que este possui 2975 imagens para treino e 500 para validação, totalizando em 3475 imagens dispostas em resolução de 1024×2048. Por sua vez, o PASCAL \textit{Panoptic Parts} possui 4998 imagens para treino e  5105 imagens para validação, as quais estão em resoluções de 387×470, totalizando à disposição de 10103 imagens.

Por fim, ainda há a disposição do conjunto de dados de partes, do qual se cita \textit{PartNet} \cite{mo2019} e \textit{PartImageNet} \cite{He2021}, sendo que o primeiro abrange a anotação de 573585 partes de instâncias, realizando a cobertura de 24 categorias de objetos, as quais também podem ser úteis para agregar ao projeto. Já o segundo, por ter sido criado com base no trabalho desenvolvido por \cite{DeGeus2021}, encontra-se disponível para o exercício das redes panópticas \textit{part-aware}, com 158 classes e por volta de 24000 imagens, visto que a fonte das imagens anotadas é o projeto \textit{ImageNet}.

Quanto aos conjuntos de dados comentados anteriormente que estarão dispostos para o meio odontológico, vale citar que esses não possuem uma anotação com classes de partes, as quais se fazem \textit{mister} para a aplicação panóptica com uso de \textit{Part-Aware}, todavia vale destacar que temos uma parceria da Faculdade de Odontologia de Araraquara (FOAr) - UNESP, a qual terá com líder o Prof. Dr. Osmir Batista de Oliveira Júnior, de modo que estudantes e especialistas da área realizem as anotações, bem como a disponibilização, de 5000 imagens de fotografias odontológicas, de modo a contribuírem para o projeto.

Além das fotografias cedidas pela parceria, vale destacar que alguns conjuntos de dados serão utilizados com o intuito de agregar em volume de imagens odontológicas, dos quais, cita-se o conjunto de dados desenvolvido por You \textit{et al.} \cite{You2020}, o qual possui 886 anotadas, o conjunto desenvolvido por Hyttinen \textit{et al.} \cite{Hyttinen2020}, com 316 imagens, sendo que 215 dessas imagens possuem uma anotação inicial e, por fim, o conjunto de dados disponível no \textit{website} da \textit{Dental Care}\footnote{\textit{Website \textit{Dental Care}} – \url{https://www.dentalcare.com/en-us/research/media-library}}, o qual cede 839 imagens odontológicas como cortesia para estudos e desenvolvimento científico. O objetivo é que todas essas 1370 imagens sejam agregadas à \textit{pipeline} de anotação e ao conjunto disponibilizado pela parceria, de modo a se tornarem úteis para a construção do modelo proposto no presente trabalho. Exemplos dos conjuntos de dados citados podem ser observados na Figura \ref{proposal:dataset:fig:2}.

\begin{figure}[H]
    \centering
    \caption{Exemplo de imagens dos conjuntos de dados odontológicos.}
    \includegraphics[width=1\textwidth]{recursos/imagens/proposal/image_odonto_dataset.png}
    \label{proposal:dataset:fig:2}

    Fonte: retirado e adaptado de \cite{You2020, Hyttinen2020} e \textit{Dental Care}, respectivamente.
\end{figure}


\subsection{Metodologia}


\subsection{Cronograma}
\label{proposal:cron}
Com o intuito de listar todas as atividades necessárias para o cumprimento do projeto, bem como definição do período em que as mesmas devem ser realizadas, foram construídas as Tabelas \ref{proposal:cron:table:1} e \ref{proposal:cron:table:2}, almejando realizar no máximo cinco  experimentos simultaneamente, considerando a complexidade, esforço e incerteza envolvida em cada um desses testes. Em relação às submissões é desejado realizar uma para conferência, objetivando  contribuir com os experimentos desenvolvidos na primeira etapa e, uma segunda, para um periódico, com o intuito de contribuir com as descobertas realizadas no experimento \rom{4}. Tem-se como objetivo realizar a escrita do trabalho em todo o período do cronograma - salvo o mês planejado para a defesa - sendo que essa atividade ocorrerá paralelamente aos demais experimentos e atividades listadas. Sendo assim, destaca-se que o prazo para defesa é em Fevereiro de 2023 e que o adiantamento no planejamento resguarda a execução de incidentes inesperados.

Por fim, vale lembrar, como citado na Seção \ref{proposal:dataset}, que o trabalho de anotação das imagens ocorrerá em parceria com estudantes e a equipe coordenada pelo Prof. Dr. Osmir Batista de Oliveira Júnior e está planejado para ocorrer paralelamente aos demais experimentos em um prazo de seis meses.

\definecolor{midgray}{gray}{.5}

\begin{table}[H]
    \centering
    \caption{Atividades a serem desenvolvidas.}
    \label{proposal:cron:table:1}
    \resizebox{\textwidth}{!}{
        \begin{tabular}{l|l}
            \textbf{Índice} & \textbf{Descrição}                                                                                                             \\ \hline
            I - 1           & Obtenção e anotação de imagens odontológicas para o treinamento e teste da rede.                                               \\
            I - 2           & Aplicação da biblioteca \textit{Detectron2} para realização de segmentação panóptica.                                          \\
            I - 3           & Modelagem da rede com o uso de \textit{part-aware panoptic segmentation}, segundo sugerido por \cite{DeGeus2021}.              \\
            I - 4           & Submissão de testes na rede modelada, com o intuito de saber como a rede tem performado.                                       \\
            II - 1          & Avaliar e adaptar (caso necessário) uma ferramenta que auxilie a anotação de imagens;                                          \\
            III - 1         & Desenvolvimento de biblioteca com métodos que auxiliam a segmentação hierárquica de componentes visuais.  \\
            IV - 1          & Transferência de aprendizado entre os conjuntos de dados disponíveis e conjunto de dado anotado.                               \\
            IV - 2          & Modificação da arquitetura base para aplicação de \textit{block-based PCA} na camada de \textit{pooling};                      \\
            V - 1           & Desenvolvimento de métodos de visualização da informação para comparar os conjuntos de dados e as métricas das redes.          \\
            V - 2           & Comparação de rede de segmentação panóptica com a rede desenvolvida.                                                 
        \end{tabular}
    }

    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}


\begin{table}[H]
    \centering
    \caption{Cronograma de atividades.}
    \label{proposal:cron:table:2}
        \begin{tabular}{|c|c|c|c|c|c|c|l|l|} 
            \hline
                                    & \multicolumn{8}{c|}{2022}                        \\ 
            \hline
            \textbf{Macroatividades}        & FEV & MAR & ABR & MAI & JUN & JUL & AGO & SET  \\ 
            \hline
            Experimento I                   & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} &     &      \\ 
            \hline
            Experimento II                  &     & \cellcolor{midgray} & \cellcolor{midgray} &     &     &     &     &      \\ 
            \hline
            Experimento III                 &     &     &     & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} &     &  \\ 
            \hline
            Experimento IV                  &     &     &     & \cellcolor{midgray} & \cellcolor{midgray} &     &     &      \\ 
            \hline
            Experimento V                   &     &     &     &     &     & \cellcolor{midgray} &     &      \\ 
            \hline
            Escrita da dissertação          & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} & \cellcolor{midgray} &  \\ 
            \hline
            Submissão para conferência      &     &     &     & \cellcolor{midgray} &     &     &     &      \\ 
            \hline
            Submissão para periódico        &     &     &     &     &     &     & \cellcolor{midgray} &      \\ 
            \hline
            Defesa                          &     &     &     &     &     &     &     & \cellcolor{midgray} \\
            \hline
        \end{tabular}
    
    \vspace*{1 cm}
    Fonte: do próprio autor.
\end{table}


\subsection{Resultados Esperados}
\label{proposal:expres}
Tendo em vista as quatro principais propostas que estão resumidas no Capítulo \ref{proposal:proposal}, vale dizer que para cada uma delas há a esperança de colher resultados.

No que diz respeito a aplicação de segmentação de componentes visuais na área odontológica, destaca-se que esse é o ponto que coloca o desenvolvimento de frente a problemas reais, com o objetivo de obter a maior descrição de cena possível no contexto odontológico, assim auxiliando profissionais da área na evidenciação de características da boca. Essa proposta foi iniciada a partir do estudo realizado por \cite{DeGeus2021} que busca, por meio do \textit{Part-Aware Panoptic Segmentation}, trazer uma visão mais holística das cenas. Sendo assim, com a meta de esclarecer visualmente esse resultado esperado, a expectativa é que por meio da entrada de uma imagem, como a representada pela Figura \ref{proposal:expres:fig:4}, tenha-se como saída da rede uma outra imagem, como a representada pela Figura \ref{proposal:expres:fig:5}.

\begin{figure}[H]
    \centering
    \caption{Exemplo de imagem de entrada para a rede a ser desenvolvida.}
    \includegraphics[height=4.3in]{recursos/imagens/proposal/boca.png}
    \label{proposal:expres:fig:4}

    Fonte: do próprio autor.
\end{figure}

\begin{figure}[H]
    \centering
    \caption{Exemplo de imagem de saída esperada pela rede a ser desenvolvida.}
    \includegraphics[height=7in]{recursos/imagens/proposal/boca_segmentada_v2.png}
    \label{proposal:expres:fig:5}

    Fonte: do próprio autor.
\end{figure}

Tendo observado e considerando as imagens de entrada e saída, respectivamente, Figura \ref{proposal:expres:fig:4}
 e \ref{proposal:expres:fig:5}, pode-se dizer que uma descrição de cena que se encaixa na representação da Figura \ref{proposal:expres:fig:5}, dadas às segmentações pode ser: Fotografia de uma boca contendo ``pele'', ``lábios'', ``bochechas'', ``gengivas'', ``palato mole'', ``língua'' e ``úvula'', como o tipo \textit{stuff}. Além disso, tem-se como parte da ``gengiva'', ``resto de comida''. Já em relação às instâncias (\textit{things}), nessa fotografia, encontram-se ``26 dentes'', sendo que é possível localizar como partes dos dentes 1, 2 e 11, ``cáries'', e como parte dos dentes 1, 2, 13 e 14, ``restaurações''.

Essa descrição de resultado esperado bem como as segmentações exemplificadas só são possíveis por meio de uma segmentação panóptica com uma segmentação voltada para as partes, o que suporta o uso do método estudado em \cite{DeGeus2021}, estabelecendo, assim, uma segmentação hierárquica de componentes visuais.

Caso a técnica de segmentação escolhida fosse a semântica, a contagem de dentes não seria possível. Por outro lado, se a segmentação escolhida fosse a de instâncias, partes como gengivas, comissuras e partes incontáveis seriam ignoradas e, por fim, caso a segmentação escolhida fosse a panóptica, desenvolvida por Kirillov \textit{et al.} \cite{Kirillov2019a}, não seria possível estabelecer uma relação entre as partes das classes, como é exemplificado na Figura \ref{proposal:expres:fig:6}, onde as cáries e a restauração são parte do ``dente 2''.

\begin{figure}[H]
    \centering
    \caption{Exemplo de hierarquia entre componentes visuais.}
    \includegraphics[width=1\textwidth]{recursos/imagens/proposal/segmentada.png}
    \label{proposal:expres:fig:6}

    Fonte: do próprio autor.
\end{figure}

Em resumo, no presente trabalho, quanto à segmentação hierárquica de componentes visuais espera-se a definição e avaliação de um arcabouço que mapeie fotografias odontológicas, retornando as estruturas da boca e, principalmente, possibilitando a contagem de dentes e a presença de cáries.
 
Em relação á contribuição com a publicação dos códigos para a segmentação hierárquica de componentes visuais é esperado que seja desenvolvido uma biblioteca que facilite e colabore com o desenvolvimento de novos métodos de segmentação panóptica com o uso de \textit{part-aware}, além de acelerar o desenvolvimento com os códigos já desenvolvidos no presente trabalho.

Acerca da avaliação e adaptação de uma ferramenta de segmentação para a anotação das imagens, vale dizer que essa é uma tarefa de suma importância, de modo a se tornar escalável a atividade de anotação de imagens para com a parceria do Prof. Osmir e equipe da Faculdade de Odontologia de Araraquara, além de trazer velocidade às fases de treino e teste do modelo a ser desenvolvido. Destarte, quanto ao ponto relatado a expectativa é que, no final das análises, uma ferramenta tenha uma análise comparativa entre as ferramentas estudadas e que uma seja determinada para as anotações recorrentes que ocorrerão nesse projeto, além de contar com contribuições para a ferramenta escolhida, caso sua implementação não seja suficiente, propondo, assim, auxiliar na segmentação com o uso de segmentação panóptica, técnica que já fora testada para essa atividade em outros estudos \cite{Elharrouss2021, Jasper2020}. Dentre as ferramentas candidatas para a execução dessa tarefa, destaca-se a desenvolvida por \cite{Jasper2020}, a qual utiliza um assistente automatizado para anotar imagens de um conjunto predefinido de segmentos com base em \textit{Mask} R-CNN (Seção \ref{instance:mask}), de modo que o trabalho do anotador diminui para confirmações se o assistente anotou corretamente o segmento, como demonstrado na Figura \ref{proposal:expres:fig:7}.

\begin{figure}[H]
    \centering
    \caption{Exemplo correção em ferramenta de anotação com imagem de entrada, reparo e anotação final, respectivamente.}
    \includegraphics[width=1\textwidth]{recursos/imagens/proposal/annotation_tool.png}
    \label{proposal:expres:fig:7}

    Fonte: retirado e adaptado de \cite{Jasper2020}.
\end{figure}

Por fim, com respeito à aplicação da técnica BPCA nas camadas de \textit{pooling} dos modelos base, a esperança é que haja uma redução de dimensionalidade mantendo as estruturas espaciais da imagem em questão, trazendo, assim, resultados positivos quanto às métricas de PQ e PartPQ. Com isso, seria definido um novo modelo para \textit{pooling}, que podemos chamar de BPCA \textit{pooling}. Ao findar do desenvolvimento desse modelo, há intenção de submete-lo a testes em relação ao modelo comum de segmentação panóptica, desenvolvido por \cite{Kirillov2019a}, além do modelo de segmentação panóptica com uso de \textit{part-aware}, desenvolvido por \cite{DeGeus2021}, objetivando resultados superiores aos atuais.